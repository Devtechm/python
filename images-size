from urllib.request import Request, urlopen
import re
from bs4 import BeautifulSoup
import pandas as pd
import requests
import shutil
import urllib.request
import time


count = 1
name = []
links = []
path = '/users//desktop/'
infile = path + "web1.txt"
f = open(infile, "w")
url = 'https://.com'

# link = 'https:///search/town-food.html'
# req = Request(link, headers={'User-Agent': 'Mozilla/5.0'})
# html_page = urlopen(req).read()

# soup = BeautifulSoup(html_page, "lxml")

# for titles in soup.find_all("a", attrs={"data-testid":"itemDescription"}):
#     for title in titles:
#         data = title.get_text()
#         if title.startswith("Town 5 "):
#             data = data.replace(' - 12/Pack', '')
#             productName = data.split(" ")[-1].strip()

#         elif title.startswith("Town Bamboo"):
#             productName = data

#         else:
#             data = data.replace('Town', '')
#             productName = data.split(" ")[1].strip()

#         name.append(productName)

# print(len(name))


while (count < 7):
    link = 'https:///search/town-food.html?page=' + str(count) 
    req = Request(link, headers={'User-Agent': 'Mozilla/5.0'})
    html_page = urlopen(req).read()
    soup = BeautifulSoup(html_page, "lxml")

    for titles in soup.find_all("a", attrs={"data-testid":"itemDescription"}):
        for title in titles:
            data = title.get_text()
            if title.startswith("Town 5 "):
                data = data.replace(' - 12/Pack', '')
                productName = data.split(" ")[-1].strip()

            elif title.startswith("Town Bamboo"):
                productName = data

            else:
                data = data.replace('Town', '')
                productName = data.split(" ")[1].strip()

            name.append(productName)


    for link in soup.find_all("img"):
        data = link.get('src')
        f.write(data)
        f.write("\n")
        links.append(data)
    
    count+=1

f.close()
# print(len(links))

count=0
outfile = path + "web2.txt"
with open(infile) as fin, open(outfile, 'w') as fout:
    for link in fin:
        if link.startswith("/images/products/"):
            format = link[-5:]
            link = link.replace('small', 'extra_large').replace('medium', 'extra_large')
            link = url + link
            fout.write(link)
            fileName = (name[count] + format).strip()
            # print(fileName)

            opener=urllib.request.build_opener()
            opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1941.0 Safari/537.36')]
            urllib.request.install_opener(opener)
            urllib.request.urlretrieve(link, fileName)
            time.sleep(3)
        
        else:
            link = link.replace(link, "")
        
        count+=1
