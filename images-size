from urllib.request import Request, urlopen
import re
from bs4 import BeautifulSoup
import pandas as pd
import requests
import shutil
import time
import urllib.request, urllib.error
from urllib.parse import urlparse


count = 1
names = []
imgTitle = []
links = []
path = '/users/don/desktop/'
infile = path + "web1.txt"
f = open(infile, "w")
url = 'https://web.com'

while (count < 7):
    site = 'https://www.web/search/town-food.html?page=' + str(count) 
    req = Request(site, headers={'User-Agent': 'Mozilla/5.0'})
    html_page = urlopen(req).read()
    soup = BeautifulSoup(html_page, "lxml")
    
    for link in soup.find_all("img"):
        img = link.get('src')
        title = link.get('alt')
        if img.startswith("/images/products/medium/"):
            f.write(url + img)
            f.write("\n")
            links.append(img)
            names.append(title)

    count+=1

f.close()

for name in names:
    count=1
    if name.startswith("Town "):
        if name.startswith("Town Bamboo"):
            name.strip()
        elif name.startswith("Town 5 "):
            name = name.replace(' - 12/Pack', '')
            name = name.split(" ")[-1].strip()

        else:
            name = name.replace('Town', '')
            name = name.split(" ")[1].strip()
        
    name.replace('/', '_')
    if name in imgTitle:
        name = name + "_" + str(count)
        count+=1            
    
    imgTitle.append(name)

count=0
outfile = path + "web2.txt"
with open(infile) as fin, open(outfile, 'w') as fout:
    for link in fin:
        if link.startswith("https://"):
            format = link[-5:]
            link = link.replace('small', 'extra_large').replace('medium', 'extra_large')
            
            try:
                req = urllib.request.urlopen(link)

            except urllib.error.HTTPError as e:                
                print(e.code)
                if e.code == 404:
                    link = link.replace('extra_', '')
                    print(link)

            except urllib.error.URLError as e:
                print("\n", link, "\n", e, "\n")

            fileName = (imgTitle[count] + format).strip().lower()
            fileName = fileName.replace('/', '-')
            opener=urllib.request.build_opener()
            opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1941.0 Safari/537.36')]
            urllib.request.install_opener(opener)
            urllib.request.urlretrieve(link, fileName)

            fout.write(link)
            time.sleep(3)
        
        count+=1

print(count)
